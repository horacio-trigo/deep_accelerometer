{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "VuFbRiXE0mT-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "dNaAM43P5t7f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsXlPmM8ywC9",
        "outputId": "a0d60414-52a7-4a37-eaae-efcd9fa39469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/accelerometer_data')\n",
        "#dataset = pd.read_csv('/content/drive/MyDrive/accelerometer_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7z315yrzpr7",
        "outputId": "df8acaac-0d9d-4aff-e47b-ddee3a82ac8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Deep accelerometer project', 'Deep accelerometer project-2.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/drive/MyDrive/accelerometer_data/Deep accelerometer project'\n",
        "os.listdir(folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NebhGmQ0EEN",
        "outputId": "df4574c5-48b9-4917-9696-7cbc21969e0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['full_df.csv',\n",
              " 'matrix_3d.npy',\n",
              " 'matrix_SEQN.csv',\n",
              " 'train_IDs.csv',\n",
              " 'test_IDs.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqn = pd.read_csv(os.path.join(folder,'matrix_SEQN.csv')).iloc[:,0].values.astype(int)\n",
        "full_df = pd.read_csv(os.path.join(folder,'full_df.csv'))\n",
        "train_ids = pd.read_csv(os.path.join(folder,'train_IDs.csv'), header=None)[0].values.astype(int)\n",
        "test_ids = pd.read_csv(os.path.join(folder,'test_IDs.csv'), header=None)[0].values.astype(int)\n",
        "sequences = np.load(os.path.join(folder,'matrix_3d.npy'))\n",
        "\n",
        "train_ids.shape\n",
        "test_ids.shape\n",
        "seqn.shape\n",
        "sequences.shape\n",
        "full_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqa_zuNv0RXG",
        "outputId": "c0cf367f-c16b-4255-85da-47120974c3e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2052,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7537,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7537, 7, 1440)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9823, 3511)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = sequences[np.nonzero(np.in1d(seqn, train_ids))[0],:,:] # index positions of seqn where the value is in train_ids\n",
        "y_train = full_df.loc[full_df['SEQN'].isin(train_ids),'TARGET_BINARY'].to_numpy()\n",
        "\n",
        "test_sequences = sequences[np.nonzero(np.in1d(seqn, test_ids))[0],:,:] # index positions of seqn where the value is in test_ids\n",
        "y_test = full_df.loc[full_df['SEQN'].isin(test_ids),'TARGET_BINARY'].to_numpy()"
      ],
      "metadata": {
        "id": "ag5N79Dg9rJ4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline 1 a)\n",
        "\n",
        "Very simple approach:\n",
        "> Simple RNN that receives the sequences of accelerometer data in full (all 7 days combined) and predicts the class label at the end\n",
        "\n",
        "## Pros\n",
        "1. Easy to implement\n",
        "\n",
        "## Cons\n",
        "1. exploding gradients due to large amount of timesteps and no mitigation for it yet"
      ],
      "metadata": {
        "id": "w8YWjnO7ecEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class AccelerometerDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        return sample, label\n"
      ],
      "metadata": {
        "id": "PLjSvpBanA4O"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_sequences.reshape(train_sequences.shape[0], -1)  # This will reshape data to (n_patients, 7*1440)\n",
        "\n",
        "\n",
        "# Create an instance of your custom dataset\n",
        "accelerometer_dataset = AccelerometerDataset(data, y_train)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(accelerometer_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "NmzYJVdSo9cJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x[:, -1, :]  # Get the last time step output\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "B7K2BqP6dHH3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(input_size = 1, # nÂº features of each timestep, currently one\n",
        "                  hidden_size = 200,\n",
        "                  output_size = 1\n",
        "                  )\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 30\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, labels) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        # Assuming your RNN expects input of shape (batch_size, seq_length, input_size)\n",
        "        outputs = model(data.unsqueeze(-1))  # Adds an input_size dimension\n",
        "        loss = criterion(outputs.squeeze(), labels)  # Squeeze to match the labels' dimensions\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "MYF3pEbWlkEt",
        "outputId": "c9088422-26d9-482b-9aa2-bfa7a986d644"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Step [0/63], Loss: 0.6956416368484497\n",
            "Epoch [1/30], Step [5/63], Loss: 0.6272827982902527\n",
            "Epoch [1/30], Step [10/63], Loss: 0.7213566303253174\n",
            "Epoch [1/30], Step [15/63], Loss: 0.6745216250419617\n",
            "Epoch [1/30], Step [20/63], Loss: 0.6562986373901367\n",
            "Epoch [1/30], Step [25/63], Loss: 0.6534990072250366\n",
            "Epoch [1/30], Step [30/63], Loss: 0.6742986440658569\n",
            "Epoch [1/30], Step [35/63], Loss: 0.7494781017303467\n",
            "Epoch [1/30], Step [40/63], Loss: 0.6679868698120117\n",
            "Epoch [1/30], Step [45/63], Loss: 0.6661444902420044\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-9772938121ee>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Assuming your RNN expects input of shape (batch_size, seq_length, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adds an input_size dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Squeeze to match the labels' dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-5c80b30407f6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the last time step output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_TANH'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    554\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                                       self.batch_first)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the model isn't really learning. probably exploding gradients because each sequence is really a lot of timesteps (it's possible to check gradient explosion by taking a look at the gradients after each loss.backward())"
      ],
      "metadata": {
        "id": "1gbxHKp2wkg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline 1 b)\n",
        "\n",
        "Very simple approach:\n",
        "- (same) Simple RNN that receives the sequences of accelerometer data in full (all 7 days combined) and predicts the class label at the end\n",
        "- gradient clipping + Xavier initialization + GRU or LSTM\n",
        "\n",
        "## Pros\n",
        "1. Easy to implement\n",
        "\n",
        "## Cons\n",
        "1. some exploration of the techniques above is required to see what works best"
      ],
      "metadata": {
        "id": "BMaFafMHse9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x[:, -1, :]  # Get the last time step output\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Apply Xavier uniform initialization to RNN weights\n",
        "        for name, param in self.rnn.named_parameters():\n",
        "            if 'weight_ih' in name:  # Weight matrix for input-to-hidden\n",
        "                init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:  # Weight matrix for hidden-to-hidden\n",
        "                init.xavier_uniform_(param.data)\n",
        "\n",
        "        # Apply Xavier uniform initialization to the weights of the fully connected layer\n",
        "        init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "        # Optionally initialize the bias terms (to 0, for example)\n",
        "        if self.fc.bias is not None:\n",
        "            init.zeros_(self.fc.bias)\n"
      ],
      "metadata": {
        "id": "awxbnvQ5sdU8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for gradient clipping apply this during the training loop after loss.backward()\n",
        "#> torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#>  optimizer.step()\n",
        "#>  ...\n"
      ],
      "metadata": {
        "id": "AP2a8wFGv7es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline 2\n",
        "\n",
        "Change the way the input data is represented. maybe reduce the number of samples per person;"
      ],
      "metadata": {
        "id": "vKoY6q4mtOPU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8AHVX29wtl0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}