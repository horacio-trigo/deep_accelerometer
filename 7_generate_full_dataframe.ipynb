{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code all the features are loaded into a single dataframe containing:\n",
    "NHANES features + \n",
    "Physical activity features (see code 5_physical_activity_feature_engineering.ipynb) + \n",
    "target binary (see code 4_building_target_variable.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NHANES dataset is stored in numerous .xpt files. These files are located in 5 different folders:\n",
    "'Demographics', 'Dietary', 'Examination', 'Laboratory', 'Questionnaire'\n",
    "\n",
    "This folder structure matches the one found at NHANES website: \n",
    "https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2013\n",
    "\n",
    "A detaile explanation of each variable can be found here:\n",
    "- Demographics: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&CycleBeginYear=2013\n",
    "- Dietary: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Dietary&CycleBeginYear=2013\n",
    "- Examination: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Examination&CycleBeginYear=2013\n",
    "- Laboratory: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Laboratory&CycleBeginYear=2013\n",
    "- Questionnaire: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&CycleBeginYear=2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import getcwd, listdir, mkdir\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = join(getcwd(), \"data\")\n",
    "xpt_location = join(data_location, \"xpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics\n",
      "['demo_h.xpt']\n",
      "Dietary\n",
      "['dr1iff_h.xpt', 'dr1tot_h.xpt', 'dr2iff_h.xpt', 'dr2tot_h.xpt', 'drxfcd_h.xpt', 'ds1ids_h.xpt', 'ds1tot_h.xpt', 'ds2ids_h.xpt', 'ds2tot_h.xpt', 'dsbi.xpt', 'dsii.xpt', 'dspi.xpt', 'dsqids_h.xpt', 'dsqtot_h.xpt']\n",
      "Examination\n",
      "['bmx_h.xpt', 'bpx_h.xpt', 'csx_h.xpt', 'dxxaac_h.xpt', 'dxxag_h.xpt', 'dxxfem_h.xpt', 'dxxfrx_h.xpt', 'dxxl1_h.xpt', 'dxxl2_h.xpt', 'dxxl3_h.xpt', 'dxxl4_h.xpt', 'dxxspn_h.xpt', 'dxxt10_h.xpt', 'dxxt11_h.xpt', 'dxxt12_h.xpt', 'dxxt4_h.xpt', 'dxxt5_h.xpt', 'dxxt6_h.xpt', 'dxxt7_h.xpt', 'dxxt8_h.xpt', 'dxxt9_h.xpt', 'dxxvfa_h.xpt', 'dxx_h.xpt', 'flxcln_h.xpt', 'mgx_h.xpt', 'ohxden_h.xpt', 'ohxper_h.xpt', 'ohxref_h.xpt', 'paxday_h.xpt', 'paxhd_h.xpt', 'paxhr_h.xpt', 'paxmin_h.xpt']\n",
      "Laboratory\n",
      "['aas_h.xpt', 'aa_h.xpt', 'alb_cr_h.xpt', 'alds_h.xpt', 'ald_h.xpt', 'amdgds_h.xpt', 'amdgyd_h.xpt', 'apob_h.xpt', 'bfrpol_h.xpt', 'biopro_h.xpt', 'cafe_h.xpt', 'cbc_h.xpt', 'chlmda_h.xpt', 'cot_h.xpt', 'cusezn_h.xpt', 'deet_h.xpt', 'ephpp_h.xpt', 'ethoxs_h.xpt', 'ethox_h.xpt', 'fastqx_h.xpt', 'fas_h.xpt', 'fldep_h.xpt', 'fldew_h.xpt', 'folate_h.xpt', 'folfms_h.xpt', 'formal_h.xpt', 'formas_h.xpt', 'ghb_h.xpt', 'hcaas_h.xpt', 'hcaa_h.xpt', 'hdl_h.xpt', 'hepa_h.xpt', 'hepbd_h.xpt', 'hepb_s_h.xpt', 'hepc_h.xpt', 'hepe_h.xpt', 'hiv_h.xpt', 'hpvp_h.xpt', 'hpvswr_h.xpt', 'hsv_h.xpt', 'ihgem_h.xpt', 'ins_h.xpt', 'mma_h.xpt', 'ogtt_h.xpt', 'orhpv_h.xpt', 'pah_h.xpt', 'pbcd_h.xpt', 'pcbpol_h.xpt', 'pernts_h.xpt', 'pernt_h.xpt', 'pfas_h.xpt', 'phthte_h.xpt', 'pooltf_h.xpt', 'pstpol_h.xpt', 'ssct_h.xpt', 'ssflrt_h.xpt', 'ssglyp_h.xpt', 'sshepc_h.xpt', 'sskl_h.xpt', 'sspfac_h.xpt', 'sspfas_h.xpt', 'sspfsu_h.xpt', 'ssphte_h.xpt', 'sssnfl_h.xpt', 'ssterp_h.xpt', 'sstoca_h.xpt', 'sstoxo_h.xpt', 'tchol_h.xpt', 'tgema_h.xpt', 'trich_h.xpt', 'trigly_h.xpt', 'tsna_h.xpt', 'tst_h.xpt', 'uass_h.xpt', 'uas_h.xpt', 'ucflow_h.xpt', 'ucots_h.xpt', 'ucot_h.xpt', 'ucpreg_h.xpt', 'uhg_h.xpt', 'uio_h.xpt', 'ums_h.xpt', 'um_h.xpt', 'uphopm_h.xpt', 'utass_h.xpt', 'utas_h.xpt', 'uvocs_h.xpt', 'uvoc_h.xpt', 'vid_h.xpt', 'vitb12_h.xpt', 'vnas_h.xpt', 'vna_h.xpt', 'vocwbs_h.xpt', 'vocwb_h.xpt']\n",
      "Questionnaire\n",
      "['acq_h.xpt', 'alq_h.xpt', 'bpq_h.xpt', 'cbq_h.xpt', 'cdq_h.xpt', 'cfq_h.xpt', 'ckq_h.xpt', 'csq_h.xpt', 'dbq_h.xpt', 'deq_h.xpt', 'diq_h.xpt', 'dlq_h.xpt', 'dpq_h.xpt', 'duq_h.xpt', 'ecq_h.xpt', 'fsq_h.xpt', 'heq_h.xpt', 'hiq_h.xpt', 'hoq_h.xpt', 'hsq_h.xpt', 'huq_h.xpt', 'imq_h.xpt', 'inq_h.xpt', 'kiq_u_h.xpt', 'mcq_h.xpt', 'ocq_h.xpt', 'ohq_h.xpt', 'osq_h.xpt', 'paq_h.xpt', 'pfq_h.xpt', 'puqmec_h.xpt', 'rhq_h.xpt', 'rxqasa_h.xpt', 'rxq_rx_h.xpt', 'slq_h.xpt', 'smqfam_h.xpt', 'smqrtu_h.xpt', 'smqshs_h.xpt', 'smq_h.xpt', 'sxq_h.xpt', 'vtq_h.xpt', 'whqmec_h.xpt', 'whq_h.xpt']\n"
     ]
    }
   ],
   "source": [
    "for folder in listdir(xpt_location):\n",
    "    print(folder)\n",
    "    print(listdir(join(xpt_location, folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Each XPR file is loaded into a dataframe. Then each dataframe is appended to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_list = []\n",
    "\n",
    "# Iterate over each folder in the xpt_location directory\n",
    "for folder in listdir(xpt_location):    \n",
    "    # Iterate over each file in the current folder\n",
    "    for name_xpt in listdir(join(xpt_location, folder)):\n",
    "        # Check if the file is not one of the DXX files (DXX files are where our target variables are calculated from), nor one of the PAX files (physical activity time series), which are processed separately and merged below (pax.csv and target.csv)\n",
    "        if not name_xpt.lower().startswith('pax') and not name_xpt.lower().startswith('dxx'):\n",
    "            # Read the xpt file as a pandas dataframe\n",
    "            df = pd.read_sas(join(xpt_location, folder, name_xpt))\n",
    "            # Check if 'SEQN' column exists in the dataframe\n",
    "            if 'SEQN' in df.columns:\n",
    "                # Each dataframe should have a single row for each SEQN value. Each SEQN value represents a subject.\n",
    "                if not df['SEQN'].duplicated().any():\n",
    "                    # Append the dataframe to the dataframes list\n",
    "                    dataframes_list.append(df)                    \n",
    "                #else:\n",
    "                    # Some dataframes have multiple entries for the same SEQN. For example some nutrition or medication dataframes, since they register multiple nutrients or medications for each subject. To include these files in the final dataframe, we would need to preprocess and aggregate the data for each subject.\n",
    "                    #print(\"There are duplicated SEQN values in the dataframe: \" + name_xpt)\n",
    "            #else:\n",
    "                # Some dataframes do not have a SEQN column. That is, rather than containing data for each subject, they provide other type of information (e.g. food codes). We do not need these dataframes, so they are not appended them to the dataframes list.\n",
    "                #print(f\"The dataframe from file {name_xpt} does not have a 'SEQN' column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Merging all dataframes to create the full dataframe with all of the NHANES variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Horacio\\OneDrive - UNIVERSIDAD DE SEVILLA\\Doctorado\\1 TRABAJOS ABIERTOS\\26 Estudio Proyecto Samsung NHANES\\nhanes_analysis\\.environment\\lib\\site-packages\\pandas\\core\\frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'WTDR2D_x', 'DRDINT_x', 'WTDRD1_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n",
      "c:\\Users\\Horacio\\OneDrive - UNIVERSIDAD DE SEVILLA\\Doctorado\\1 TRABAJOS ABIERTOS\\26 Estudio Proyecto Samsung NHANES\\nhanes_analysis\\.environment\\lib\\site-packages\\pandas\\core\\frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'URXUCR_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n",
      "c:\\Users\\Horacio\\OneDrive - UNIVERSIDAD DE SEVILLA\\Doctorado\\1 TRABAJOS ABIERTOS\\26 Estudio Proyecto Samsung NHANES\\nhanes_analysis\\.environment\\lib\\site-packages\\pandas\\core\\frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'WTSA2YR_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n",
      "c:\\Users\\Horacio\\OneDrive - UNIVERSIDAD DE SEVILLA\\Doctorado\\1 TRABAJOS ABIERTOS\\26 Estudio Proyecto Samsung NHANES\\nhanes_analysis\\.environment\\lib\\site-packages\\pandas\\core\\frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'WTFSM_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n",
      "c:\\Users\\Horacio\\OneDrive - UNIVERSIDAD DE SEVILLA\\Doctorado\\1 TRABAJOS ABIERTOS\\26 Estudio Proyecto Samsung NHANES\\nhanes_analysis\\.environment\\lib\\site-packages\\pandas\\core\\frame.py:9190: FutureWarning: Passing 'suffixes' which cause duplicate columns {'URXUCR_x', 'WTFSM_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    }
   ],
   "source": [
    "# Start with the first dataframe\n",
    "full_df = dataframes_list[0]\n",
    "\n",
    "# Loop through the rest and merge based on SEQN\n",
    "for df in dataframes_list[1:]:\n",
    "    full_df = full_df.merge(df, on='SEQN', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: The previous cells produces warnings since there are column name duplicates. That is, there are columns (other than SEQN) in the DataFrames that have the same name but are from different files, the merge operation will append suffixes (_x, _y, etc.) to make the names unique. This happens for example in nutrition data, where the same variables where measured in different days, and each day was stored in a different dataframe. Be aware of this if you expect or see columns with these appended names in the merged DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Including the Physical Activity features in the full dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax_df = pd.read_csv('pax.csv')\n",
    "pax_df = pax_df.drop(columns=['Unnamed: 0']) #This column is not needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.merge(pax_df, on='SEQN', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Including the target variable at the end of the full dataframe. (TARGET_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.merge(target_df, on='SEQN', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fixing read_sas bug. More info: https://github.com/pandas-dev/pandas/issues/30051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613351\n"
     ]
    }
   ],
   "source": [
    "print((full_df == 5.397605346934028e-79).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=full_df.replace(5.397605346934028e-79,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((full_df == 5.397605346934028e-79).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1616733\n"
     ]
    }
   ],
   "source": [
    "print((full_df == 0).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save full dataframe into a csv file and a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full dataframe into a csv file and a pickle file\n",
    "full_df.to_csv('full_df.csv', index=False)\n",
    "full_df.to_pickle('full_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
